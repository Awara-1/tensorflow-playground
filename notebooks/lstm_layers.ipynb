{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation with tf.compat.v1.nn.rnn_cell.LSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### inputs to LSTM has the following shape [batch, timesteps, feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 1024, 2)\n",
    "x = tf.random.normal(input_shape, stddev=0.1)\n",
    "x = tf.constant(x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=32, use_peepholes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(tf.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_units: typing.Union[typing.List[int], int],\n",
    "                 use_peepholes: bool,\n",
    "                 name: str = None):\n",
    "        super(LSTM, self).__init__(name)\n",
    "        \n",
    "        # if num_units is given as int, ensure it's set to a list\n",
    "        if isinstance(num_units, int):\n",
    "            num_units = [num_units]\n",
    "        else:\n",
    "            num_units = num_units      \n",
    "        \n",
    "        self.num_units = num_units\n",
    "        self.use_peepholes = use_peepholes\n",
    "        \n",
    "        self.lstm_layers = [tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=size, \n",
    "                                                              use_peepholes=self.use_peepholes) for size in self.num_units]\n",
    "        self.multi_lstm_cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell(self.lstm_layers)\n",
    "                \n",
    "    def __call__(self, x_in):\n",
    "        \n",
    "        return tf.compat.v1.nn.dynamic_rnn(cell=self.multi_lstm_cell, inputs=x_in, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = LSTM(num_units=32, use_peepholes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, state = lstm_layer(x_in=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-rr-denoising-tf2",
   "language": "python",
   "name": "env-rr-denoising-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
