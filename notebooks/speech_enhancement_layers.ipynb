{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of \"Speech enhancement by LSTM-based noise suppression followed by CNN-based speech restoration\" paper - https://link.springer.com/article/10.1186/s13634-020-00707-1\n",
    "\n",
    "##### Implementation of individual model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's assume we have an input of [batch_size, sequence_length, nr_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 1024, 2)\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.constant(x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup individual layers and test that they work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "    \n",
    "    def __init__(self, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False # is built flag for dynamic input size inference\n",
    "        self.out_features = out_features\n",
    "        \n",
    "    def __call__(self, x_in):\n",
    "        if not self.is_built:\n",
    "            self.w = tf.Variable(\n",
    "                tf.random.normal([x.shape[-1], self.out_features]), name='w')\n",
    "            self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
    "            self.is_built = True\n",
    "        \n",
    "        x_hat = tf.matmul(x, self.w) + self.b\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = Dense(out_features=425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_output = dense_layer(x)\n",
    "dense_layer_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(tf.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_units: typing.Union[typing.List[int], int],\n",
    "                 use_peepholes: bool,\n",
    "                 name: str = None):\n",
    "        super(LSTM, self).__init__(name)\n",
    "        \n",
    "        # if num_units is given as int, ensure it's set to a list\n",
    "        if isinstance(num_units, int):\n",
    "            num_units = [num_units]\n",
    "        else:\n",
    "            num_units = num_units      \n",
    "        \n",
    "        self.num_units = num_units\n",
    "        self.use_peepholes = use_peepholes\n",
    "        \n",
    "        self.lstm_layers = [tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=size, \n",
    "                                                              use_peepholes=self.use_peepholes) for size in self.num_units]\n",
    "        self.multi_lstm_cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell(self.lstm_layers)\n",
    "                \n",
    "    def __call__(self, x_in):\n",
    "        \n",
    "        return tf.compat.v1.nn.dynamic_rnn(cell=self.multi_lstm_cell, inputs=x_in, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = LSTM(num_units=425, use_peepholes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer_output, lstm_layer_state = lstm_layer(x_in=dense_layer_output)\n",
    "lstm_layer_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(tf.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "               nr_filters: int,\n",
    "               kernel: int,\n",
    "               stride: int,\n",
    "               use_bias: bool,\n",
    "               name = None\n",
    "              ):\n",
    "        \n",
    "        super(Conv1D, self).__init__(name)\n",
    "        \n",
    "        self.nr_filters = nr_filters\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "        self.is_built: bool = False\n",
    "        \n",
    "        self.W: tf.Tensor = None \n",
    "        self.b: tf.Tensor = None\n",
    "            \n",
    "    def __call__(self, x_in):\n",
    "        \n",
    "        if not self.is_built:\n",
    "            in_channels = x_in.shape[-1]\n",
    "            filter_weights_shape = (self.kernel, in_channels, self.nr_filters)\n",
    "            \n",
    "            self.W = tf.Variable(tf.random.normal(filter_weights_shape, stddev=0.1),\n",
    "                                trainable=True,\n",
    "                                dtype = tf.float32,\n",
    "                                name = \"conv1d_filters\")\n",
    "            if self.use_bias:\n",
    "                self.b = tf.Variable(tf.random.normal([self.nr_filters]))\n",
    "            \n",
    "            self.is_built = True\n",
    "            \n",
    "        if self.use_bias:\n",
    "            return tf.add(\n",
    "                tf.nn.conv1d(\n",
    "                input=x_in,\n",
    "                filters=self.W,\n",
    "                stride=self.stride,\n",
    "                padding=\"SAME\"\n",
    "                ),\n",
    "                self.b,\n",
    "                name=\"conv1d_layer_with_bias\"\n",
    "            )\n",
    "        else:\n",
    "            return tf.nn.conv1d(\n",
    "                input=x_in,\n",
    "                filters=self.W,\n",
    "                stride=self.stride,\n",
    "                padding=\"SAME\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_layer = Conv1D(nr_filters=88, kernel=24, stride=1, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_layer(x_in=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pooling_1d = tf.keras.layers.MaxPool1D(pool_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pooling_1d(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1D Transpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_transpose_layer = tf.keras.layers.Conv1DTranspose(filters=2*88, kernel_size=24, strides=1, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_transpose_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_transpose_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampling_layer = tf.keras.layers.UpSampling1D(size=2)\n",
    "upsampling_layer(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-mlflow-examples",
   "language": "python",
   "name": "env-mlflow-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
