{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of \"Deep Residual Learning for Image Recognition\" paper - https://ieeexplore.ieee.org/document/7780459\n",
    "\n",
    "##### Training of residual network imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.residual_learning_imagenet import ResidualImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10 # for the sake of dummy training, set to 50, paper mentions 60e^4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PORTN = 0.8 # portion of train data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fun(y_true, y_pred):\n",
    "    return tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: need to upgrade to tf 2.11 for weight decay parameter\n",
    "def sgd_optimizer(learning_rate):\n",
    "    return tf.keras.optimizers.SGD(\n",
    "        learning_rate=learning_rate,\n",
    "        momentum=0.9,\n",
    "        name='SGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_batch, y_batch):\n",
    "    \"\"\"\n",
    "        Training step for each training dataset batch\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_in=x_batch)\n",
    "        loss_value = loss_fun(y_true=y_batch, y_pred=y_pred)\n",
    "    \n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, x_batch, y_batch):\n",
    "    \"\"\"\n",
    "        Test step for each test dataset batch\n",
    "    \"\"\"\n",
    "    y_pred = model(x_in=x_batch)\n",
    "    return loss_fun(y_true=y_batch, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_seq_desc_order(seq):\n",
    "    return all(earlier >= later for earlier, later in zip(seq, seq[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_same(seq):\n",
    "    return len(set(seq)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, learning_rate: float, lr_factor: int, nr_epochs_for_lr_change: int):\n",
    "\n",
    "    mean_train_epoch_losses = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"working on epoch: {epoch}...\")\n",
    "        losses_train = []\n",
    "        for train_idx, (x_batch_train, y_batch_train) in enumerate(zip(train_data_x, train_data_y)):\n",
    "            optimizer = sgd_optimizer(learning_rate=learning_rate)\n",
    "            loss_train_value = train_step(model=model, optimizer=optimizer, x_batch=x_batch_train, y_batch=y_batch_train)\n",
    "            losses_train.append(loss_train_value.numpy())\n",
    "            print(f\"Training step is {train_idx}\")\n",
    "\n",
    "            if train_idx % 100 == 0:\n",
    "                print(f\"Loss at step {train_idx} is {loss_train_value.numpy():.2f}.\")\n",
    "        \n",
    "        mean_train_epoch_losses.append(np.mean(losses_train))\n",
    "        print(f\"Finished epoch training nr: {epoch}. Running test inference...\")\n",
    "        \n",
    "        if len(mean_train_epoch_losses) > nr_epochs_for_lr_change:\n",
    "            # get last three results\n",
    "            print(f\"last {nr_epochs_for_lr_change} mean epoch losses train results are: {mean_train_epoch_losses[-nr_epochs_for_lr_change:]}\")\n",
    "            if all_same(seq=mean_train_epoch_losses[-nr_epochs_for_lr_change:]): # check if there has been no decrease for more than nr_epochs_for_lr_change epochs\n",
    "                learning_rate = learning_rate*lr_factor # reduce by learning factor\n",
    "                print(f\"updated learning rate is: {learning_rate}\")\n",
    "\n",
    "        losses_test = []\n",
    "        for test_idx, (x_batch_test, y_batch_test) in enumerate(zip(test_data_x, test_data_y)):\n",
    "            loss_test_value = test_step(model=model, x_batch=x_batch_test, y_batch=y_batch_test)\n",
    "            losses_test.append(loss_test_value.numpy())\n",
    "            print(f\"Test step is {test_idx}\")\n",
    "\n",
    "        print(f\"Average (mean) epoch test set loss: {np.mean(losses_test):.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Image Net Dummy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_x = (NUM_SAMPLES, 500, 500, 3)\n",
    "input_shape_y = (NUM_SAMPLES, NUM_CLASSES)\n",
    "\n",
    "data_x = tf.random.normal(input_shape_x)\n",
    "data_x = tf.constant(data_x, dtype=tf.float32)\n",
    "\n",
    "data_y = tf.one_hot(np.arange(1, NUM_SAMPLES+1, 1) , NUM_CLASSES, dtype=tf.int32) # dummy/random 1-hot encoded class outputs\n",
    "data_y = tf.constant(data_y, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(input_shape_x[0]*TRAIN_PORTN)\n",
    "\n",
    "train_data_x = tf.data.Dataset.from_tensor_slices(data_x[:train_size])\n",
    "train_data_x = train_data_x.batch(BATCH_SIZE)\n",
    "\n",
    "train_data_y = tf.data.Dataset.from_tensor_slices(data_y[:train_size])\n",
    "train_data_y = train_data_y.batch(BATCH_SIZE)\n",
    "\n",
    "test_data_x = tf.data.Dataset.from_tensor_slices(data_x[train_size:])\n",
    "test_data_x = test_data_x.batch(BATCH_SIZE)\n",
    "\n",
    "test_data_y = tf.data.Dataset.from_tensor_slices(data_y[train_size:])\n",
    "test_data_y = test_data_y.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_image_net = ResidualImageNet(num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on epoch: 0...\n",
      "Training step is 0\n",
      "Loss at step 0 is 15.32.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 0. Running test inference...\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 1...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 1. Running test inference...\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 2...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 2. Running test inference...\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 3...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 3. Running test inference...\n",
      "last 3 mean epoch losses train results are: [15.916619, 15.916619, 15.916619]\n",
      "updated learning rate is: 0.010000000000000002\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 4...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 4. Running test inference...\n",
      "last 3 mean epoch losses train results are: [15.916619, 15.916619, 15.916619]\n",
      "updated learning rate is: 0.0010000000000000002\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 5...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 5. Running test inference...\n",
      "last 3 mean epoch losses train results are: [15.916619, 15.916619, 15.916619]\n",
      "updated learning rate is: 0.00010000000000000003\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 6...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 6. Running test inference...\n",
      "last 3 mean epoch losses train results are: [15.916619, 15.916619, 15.916619]\n",
      "updated learning rate is: 1.0000000000000004e-05\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 7...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 7. Running test inference...\n",
      "last 3 mean epoch losses train results are: [15.916619, 15.916619, 15.916619]\n",
      "updated learning rate is: 1.0000000000000004e-06\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 8...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 8. Running test inference...\n",
      "last 3 mean epoch losses train results are: [15.916619, 15.916619, 15.916619]\n",
      "updated learning rate is: 1.0000000000000005e-07\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n",
      "working on epoch: 9...\n",
      "Training step is 0\n",
      "Loss at step 0 is 14.51.\n",
      "Training step is 1\n",
      "Training step is 2\n",
      "Training step is 3\n",
      "Training step is 4\n",
      "Training step is 5\n",
      "Training step is 6\n",
      "Training step is 7\n",
      "Finished epoch training nr: 9. Running test inference...\n",
      "last 3 mean epoch losses train results are: [15.916619, 15.916619, 15.916619]\n",
      "updated learning rate is: 1.0000000000000005e-08\n",
      "Test step is 0\n",
      "Test step is 1\n",
      "Average (mean) epoch test set loss: 16.12.\n"
     ]
    }
   ],
   "source": [
    "train_model(model=residual_image_net, learning_rate=0.1, lr_factor=0.1, nr_epochs_for_lr_change=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-mlflow-examples",
   "language": "python",
   "name": "env-mlflow-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
