{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of \"Speech enhancement by LSTM-based noise suppression followed by CNN-based speech restoration\" paper - https://link.springer.com/article/10.1186/s13634-020-00707-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of Speech Restoration Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.speech_enhancement_layers import Conv1D\n",
    "from ipynb.fs.full.speech_enhancement_noise_suppression_module import NoiseSuppressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's assume we have an input of [batch_size, sequence_length, nr_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 1024, 2)\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.constant(x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Restoration Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The speech restoration module makes use of con1d, conv1d transpose, max pooling and upsampling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Below is the class for the first block in figure 3 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechRestorationNetworkBlock1(tf.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                nr_conv_filters: int,\n",
    "                conv_filter_size: int,\n",
    "                name: str = None\n",
    "                ):\n",
    "        super(SpeechRestorationNetworkBlock1, self).__init__(name)\n",
    "        \n",
    "        self.conv1D_1 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.conv1D_2 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        \n",
    "        self.max_pooling_1 = tf.keras.layers.MaxPool1D(pool_size=2)\n",
    "        self.conv1D_3 = Conv1D(nr_filters=2*nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.conv1D_4 = Conv1D(nr_filters=2*nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        \n",
    "        self.max_pooling_2 = tf.keras.layers.MaxPool1D(pool_size=2)\n",
    "        \n",
    "        self.conv1D_5 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.upsampling_1 = tf.keras.layers.UpSampling1D(size=2)\n",
    "        \n",
    "        self.conv1D_6 = Conv1D(nr_filters=2*nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.conv1D_7 = Conv1D(nr_filters=2*nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        \n",
    "        self.upsampling_2 = tf.keras.layers.UpSampling1D(size=2)\n",
    "        self.conv1D_8 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.conv1D_9 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "\n",
    "        self.conv1D_last = Conv1D(nr_filters=2, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        \n",
    "    \n",
    "    def __call__(self, x_in: tf.Tensor):\n",
    "        \n",
    "        x = self.conv1D_1(x_in)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_2(x) # this will be addeed at a later stage in model\n",
    "        temp1 = tf.nn.leaky_relu(x)\n",
    "        x = self.max_pooling_1(temp1)\n",
    "        x = self.conv1D_3(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_4(x) # this will be added at a later stage in model\n",
    "        temp2 = tf.nn.leaky_relu(x)\n",
    "        x = self.max_pooling_2(temp2)\n",
    "        x = self.conv1D_5(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.upsampling_1(x)\n",
    "        x = self.conv1D_6(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_7(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        add_1 = tf.add(x, temp2)\n",
    "        x = self.upsampling_2(add_1)\n",
    "        x = self.conv1D_8(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_9(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        add_2 = tf.add(x, temp1)\n",
    "        x = self.conv1D_last(add_2)\n",
    "        return tf.nn.leaky_relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_restoration_network_block1 = SpeechRestorationNetworkBlock1(nr_conv_filters=88, conv_filter_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1_output = speech_restoration_network_block1(x_in=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Below is the class for the first block in figure 4 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechRestorationNetworkBlock2(tf.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                nr_conv_filters: int,\n",
    "                conv_filter_size: int,\n",
    "                name: str = None\n",
    "                ):\n",
    "        super(SpeechRestorationNetworkBlock2, self).__init__(name)\n",
    "        \n",
    "        self.conv1D_1 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.conv1D_2 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=2, use_bias=True)\n",
    "        \n",
    "        self.conv1D_3 = Conv1D(nr_filters=2*nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.conv1D_4 = Conv1D(nr_filters=2*nr_conv_filters, kernel=conv_filter_size, stride=2, use_bias=True)\n",
    "        \n",
    "        self.conv1D_5 = Conv1D(nr_filters=nr_conv_filters, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        self.conv1D_transpose_1 = tf.keras.layers.Conv1DTranspose(filters=2*nr_conv_filters, kernel_size=conv_filter_size, strides=2, padding=\"same\") # padding must be set to same to ensure output shape = input shape\n",
    "        \n",
    "        self.conv1D_transpose_2 = tf.keras.layers.Conv1DTranspose(filters=2*nr_conv_filters, kernel_size=conv_filter_size, strides=1, padding=\"same\")\n",
    "        self.conv1D_transpose_3 = tf.keras.layers.Conv1DTranspose(filters=nr_conv_filters, kernel_size=conv_filter_size, strides=2, padding=\"same\")\n",
    "        \n",
    "        self.conv1D_transpose_4 = tf.keras.layers.Conv1DTranspose(filters=nr_conv_filters, kernel_size=conv_filter_size, strides=1, padding=\"same\")\n",
    "        \n",
    "        self.conv1D_last = Conv1D(nr_filters=2, kernel=conv_filter_size, stride=1, use_bias=True)\n",
    "        \n",
    "    def __call__(self, x_in: tf.Tensor):\n",
    "        x = self.conv1D_1(x_in)\n",
    "        temp1 = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_2(temp1)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_3(x)\n",
    "        temp2 = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_4(temp2)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_5(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_transpose_1(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        add_1 = tf.add(x, temp2)\n",
    "        x = self.conv1D_transpose_2(add_1)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_transpose_3(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        add_2 = tf.add(x, temp1)\n",
    "        x = self.conv1D_transpose_4(add_2)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv1D_last(x)\n",
    "        return tf.nn.leaky_relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_restoration_network_block2 = SpeechRestorationNetworkBlock2(nr_conv_filters=88, conv_filter_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_restoration_network_block2(x_in=block1_output) # input to block 2 is output from block 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bring both blocks into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechRestorationNetwork(tf.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                nr_conv_filters: int,\n",
    "                conv_filter_size: int,\n",
    "                name: str = None):\n",
    "        super(SpeechRestorationNetwork, self).__init__(name)\n",
    "        \n",
    "        self.speech_restoration_network_block1 = SpeechRestorationNetworkBlock1(nr_conv_filters=88, conv_filter_size=24)\n",
    "        self.speech_restoration_network_block2 = SpeechRestorationNetworkBlock2(nr_conv_filters=88, conv_filter_size=24)\n",
    "        \n",
    "    def __call__(self, x_in: tf.Tensor):\n",
    "        x = self.speech_restoration_network_block1(x_in)\n",
    "        return self.speech_restoration_network_block2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_restoration_network = SpeechRestorationNetwork(nr_conv_filters=88, conv_filter_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_suppressor = NoiseSuppressor(output_size=2) # build noise suppressor to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_restoration_network(x_in=noise_suppressor(x_in=x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-mlflow-examples",
   "language": "python",
   "name": "env-mlflow-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
